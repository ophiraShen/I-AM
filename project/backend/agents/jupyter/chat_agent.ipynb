{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# 设置关键库的日志级别\n",
    "loggers_to_quiet = [\n",
    "    'httpx',           # HTTP 客户端库\n",
    "    'httpcore',        # HTTP 核心库\n",
    "    'urllib3',         # HTTP 客户端库\n",
    "    'requests',        # HTTP 客户端库\n",
    "    'openai',          # OpenAI API 库\n",
    "    'torch',           # PyTorch\n",
    "    'transformers',    # Hugging Face Transformers\n",
    "    'langchain',       # LangChain\n",
    "    'langchain_core',  # LangChain Core\n",
    "    'tqdm',           # 进度条库\n",
    "    'numba',          # Numba\n",
    "    'matplotlib',      # Matplotlib\n",
    "]\n",
    "\n",
    "for logger_name in loggers_to_quiet:\n",
    "    logging.getLogger(logger_name).setLevel(logging.WARNING)\n",
    "\n",
    "# 如果还有调试信息，可以设置根日志记录器的级别\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/autodl-tmp/I-AM/project/backend/agents')\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing import TypedDict, Annotated, Literal, NotRequired, List, Optional, Any\n",
    "from pydantic import BaseModel, Field, ConfigDict, field_validator\n",
    "\n",
    "\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_log(current_log, new_log: str) -> list[str]:\n",
    "    if current_log is None:\n",
    "        return [new_log] if isinstance(new_log, str) else new_log\n",
    "    elif isinstance(current_log, list):\n",
    "        return current_log + [new_log] if isinstance(new_log, str) else new_log\n",
    "    elif isinstance(current_log, str):\n",
    "        return [current_log, new_log] if isinstance(new_log, str) else new_log\n",
    "    else:\n",
    "        return [new_log] if isinstance(new_log, str) else new_log\n",
    "\n",
    "class OverallState(BaseModel):\n",
    "    messages: Annotated[List[AnyMessage], add_messages] = Field(default_factory=list, title=\"对话列表\")\n",
    "    route: Literal[\"affirmation\", \"meditation\", \"normal_chat\"] = Field(default=\"normal_chat\", title=\"当前路由\")\n",
    "    log: Annotated[List[str], add_log] = Field(default_factory=list, title=\"日志列表\")\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    @field_validator('log', mode='before')\n",
    "    def validate_log(cls, v, info):\n",
    "        if v is None or (isinstance(v, list) and len(v) == 0):\n",
    "            return []\n",
    "        if 'log' in info.data:\n",
    "            return add_log(info.data['log'], v)\n",
    "        return [v] if isinstance(v ,str) else v\n",
    "        \n",
    "\n",
    "    @field_validator('messages', mode='before')\n",
    "    def validate_messages(cls, v, info):\n",
    "        if 'messages' in info.data:\n",
    "            return add_messages(info.data['messages'], v)\n",
    "        else:\n",
    "            return v if isinstance(v, list) else [v]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 肯定语模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from affirmation_agent import AffirmationAgent\n",
    "\n",
    "config_path = '/root/autodl-tmp/I-AM/project/backend/config/affirmation.yaml'\n",
    "\n",
    "affirmation_agent = AffirmationAgent(config_path).create_graph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 冥想模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_meditation(state: OverallState) -> OverallState:\n",
    "#     return {\"route\": \"meditation\", \"log\": \"冥想音频已生成\"}\n",
    "\n",
    "# meditation_workflow = StateGraph(OverallState)\n",
    "# meditation_workflow.add_node(\"create_meditation\", create_meditation)\n",
    "# meditation_workflow.add_edge(START, \"create_meditation\")\n",
    "# meditation_workflow.add_edge(\"create_meditation\", END)\n",
    "\n",
    "# meditation_agent = meditation_workflow.compile()\n",
    "\n",
    "from meditation_agent import create_meditation_graph\n",
    "\n",
    "meditation_agent = create_meditation_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"deepseek-chat\", openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"), openai_api_base='https://api.deepseek.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户反馈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_feadback_agent(state: OverallState) -> OverallState:\n",
    "    if state.route == \"affirmation\":\n",
    "        user_approval = input(\"是否打开肯定语？(yes/no):\")\n",
    "        if user_approval.lower() == \"yes\":\n",
    "            return {\"route\": \"affirmation\", \"log\": \"用户同意打开肯定语\"}\n",
    "        else:\n",
    "            return {\"route\": \"normal_chat\", \"log\": \"用户不同意打开肯定语\"}\n",
    "    elif state.route == \"meditation\":\n",
    "        user_approval = input(\"是否打开冥想音频？(yes/no):\")\n",
    "        if user_approval.lower() == \"yes\":\n",
    "            return {\"route\": \"meditation\", \"log\": \"用户同意打开冥想音频\"}\n",
    "        else:\n",
    "            return {\"route\": \"normal_chat\", \"log\": \"用户不同意打开冥想音频\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 路由"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(TypedDict):\n",
    "    route: Literal[\"affirmation\", \"meditation\", \"normal_chat\"]\n",
    "\n",
    "with open('../prompts/router_prompt.txt', 'r') as file:\n",
    "    router_prompt = file.read().strip()\n",
    "\n",
    "router_model = llm.with_structured_output(Router)\n",
    "\n",
    "def router_node(state: OverallState) -> OverallState:    \n",
    "    messages = [SystemMessage(content=router_prompt)] + state.messages\n",
    "    route = router_model.invoke(messages)\n",
    "    return {\"route\": route[\"route\"], \"log\": \"路由已确定\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主对话模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../prompts/chat_prompt.txt', 'r') as file:\n",
    "    chat_prompt = file.read().strip()\n",
    "\n",
    "normal_system_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", chat_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def normal_chat_agent(state: OverallState) -> OverallState:\n",
    "    prompt = normal_system_prompt.partial(route=state.route, log=\"\\n\".join(state.log))\n",
    "    normal_llm = prompt | llm\n",
    "    response = normal_llm.invoke(state.messages)\n",
    "    return {\"route\": \"normal_chat\", \"messages\": [response], \"log\": \"常规对话已生成\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_condition_edge(state: OverallState):\n",
    "    if state.route == \"affirmation\" or state.route == \"meditation\":\n",
    "        return \"user_feadback_agent\"\n",
    "    elif state.route == \"normal_chat\":\n",
    "        return \"normal_chat_agent\"\n",
    "    \n",
    "def user_feadback_condition_edge(state: OverallState):\n",
    "    if state.route == \"affirmation\":\n",
    "        return \"affirmation_agent\"\n",
    "    elif state.route == \"meditation\":\n",
    "        return \"meditation_agent\"\n",
    "    else:\n",
    "        return \"normal_chat_agent\"\n",
    "\n",
    "main_dialogue_workflow = StateGraph(OverallState)\n",
    "main_dialogue_workflow.add_node(\"router_node\", router_node)\n",
    "main_dialogue_workflow.add_node(\"user_feadback_agent\", user_feadback_agent)\n",
    "main_dialogue_workflow.add_node(\"normal_chat_agent\", normal_chat_agent)\n",
    "main_dialogue_workflow.add_node(\"affirmation_agent\", affirmation_agent)\n",
    "main_dialogue_workflow.add_node(\"meditation_agent\", meditation_agent)\n",
    "\n",
    "main_dialogue_workflow.add_conditional_edges(\n",
    "    \"router_node\",\n",
    "    router_condition_edge,\n",
    "    {\n",
    "        \"user_feadback_agent\": \"user_feadback_agent\",\n",
    "        \"normal_chat_agent\": \"normal_chat_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "main_dialogue_workflow.add_conditional_edges(\n",
    "    \"user_feadback_agent\",\n",
    "    user_feadback_condition_edge,\n",
    "    {\n",
    "        \"affirmation_agent\": \"affirmation_agent\",\n",
    "        \"meditation_agent\": \"meditation_agent\",\n",
    "        \"normal_chat_agent\": \"normal_chat_agent\"\n",
    "    }\n",
    ")\n",
    "main_dialogue_workflow.add_edge(\"affirmation_agent\", \"normal_chat_agent\")\n",
    "main_dialogue_workflow.add_edge(\"meditation_agent\", \"normal_chat_agent\")\n",
    "main_dialogue_workflow.add_edge(START, \"router_node\")\n",
    "main_dialogue_workflow.add_edge(\"normal_chat_agent\", END)\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "main_dialogue_graph = main_dialogue_workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Setting xray to 1 will show the internal structure of the nested graph\n",
    "display(Image(main_dialogue_graph.get_graph(xray=2).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"002\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"你好\")]}\n",
    "for chunk in main_dialogue_graph.stream(inputs, config=config, stream_mode=\"values\"):\n",
    "    chunk['messages'][-1].pretty_print()\n",
    "\n",
    "# state = main_dialogue_graph.get_state(config)\n",
    "# if state.next:\n",
    "#     if state.next[0] == \"diary_agent\":\n",
    "#         user_approval = input(\"是否打开显化日记本？(yes/no):\")\n",
    "#         if user_approval.lower() == \"yes\":\n",
    "#             for chunk in main_dialogue_graph.stream(None, config=config, stream_mode=\"messages\"):\n",
    "#                 print(chunk[0].content, end=\"\")\n",
    "#     elif state.next[0] == \"meditation_agent\":\n",
    "#         user_approval = input(\"是否打开冥想音频？(yes/no):\")\n",
    "#         if user_approval.lower() == \"yes\":\n",
    "#             for chunk in main_dialogue_graph.stream(None, config=config, stream_mode=\"messages\"):\n",
    "#                 print(chunk[0].content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk['messages'][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for state in main_dialogue_graph.get_state_history(config):\n",
    "#     print(state.values[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# # 列出所有当前的 loggers\n",
    "# for name, logger in logging.root.manager.loggerDict.items():\n",
    "#     print(f\"Logger name: {name}\")\n",
    "#     if isinstance(logger, logging.Logger):\n",
    "#         print(f\"  Level: {logger.level}\")\n",
    "#         print(f\"  Handlers: {logger.handlers}\")\n",
    "#         print(f\"  Parent: {logger.parent}\")\n",
    "#     print(\"---\")\n",
    "\n",
    "# # 然后根据发现的 logger 名称设置级别\n",
    "# # 例如，如果发现是 'api_client' 在输出这些日志：\n",
    "# # logging.getLogger('api_client').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对话存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversation_json = {\n",
    "#     \"messages\": []\n",
    "# }\n",
    "\n",
    "# for d in chunk['messages']:\n",
    "#     if type(d).__name__ == 'HumanMessage':\n",
    "#         item = {\"role\": \"user\", \"content\": d.content}\n",
    "#     elif type(d).__name__ == 'AIMessage':\n",
    "#         item = {\"role\": \"assistant\", \"content\": d.content}\n",
    "#     else:\n",
    "#         continue\n",
    "#     conversation_json['messages'].append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('conversations_data/meditation.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(conversation_json, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifest_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
