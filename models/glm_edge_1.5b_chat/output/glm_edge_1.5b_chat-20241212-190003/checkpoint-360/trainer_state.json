{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.96398891966759,
  "eval_steps": 90,
  "global_step": 360,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11080332409972299,
      "grad_norm": 10.781506538391113,
      "learning_rate": 1.4705882352941177e-05,
      "loss": 15.845,
      "step": 10
    },
    {
      "epoch": 0.22160664819944598,
      "grad_norm": 10.163567543029785,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 15.4811,
      "step": 20
    },
    {
      "epoch": 0.33240997229916897,
      "grad_norm": 9.760068893432617,
      "learning_rate": 4.411764705882353e-05,
      "loss": 14.3613,
      "step": 30
    },
    {
      "epoch": 0.44321329639889195,
      "grad_norm": 10.3185396194458,
      "learning_rate": 5.882352941176471e-05,
      "loss": 13.0578,
      "step": 40
    },
    {
      "epoch": 0.554016620498615,
      "grad_norm": 3.908031702041626,
      "learning_rate": 7.352941176470589e-05,
      "loss": 12.136,
      "step": 50
    },
    {
      "epoch": 0.6648199445983379,
      "grad_norm": 3.8275136947631836,
      "learning_rate": 8.823529411764706e-05,
      "loss": 11.2791,
      "step": 60
    },
    {
      "epoch": 0.775623268698061,
      "grad_norm": 3.6770546436309814,
      "learning_rate": 9.947643979057593e-05,
      "loss": 10.5825,
      "step": 70
    },
    {
      "epoch": 0.8864265927977839,
      "grad_norm": 3.976257801055908,
      "learning_rate": 9.68586387434555e-05,
      "loss": 9.7961,
      "step": 80
    },
    {
      "epoch": 0.997229916897507,
      "grad_norm": 3.7707250118255615,
      "learning_rate": 9.424083769633509e-05,
      "loss": 9.4834,
      "step": 90
    },
    {
      "epoch": 0.997229916897507,
      "eval_loss": 2.3372445106506348,
      "eval_runtime": 6.4693,
      "eval_samples_per_second": 57.966,
      "eval_steps_per_second": 7.265,
      "step": 90
    },
    {
      "epoch": 1.0997229916897506,
      "grad_norm": 3.228750705718994,
      "learning_rate": 9.162303664921467e-05,
      "loss": 8.617,
      "step": 100
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 3.459273338317871,
      "learning_rate": 8.900523560209425e-05,
      "loss": 9.2613,
      "step": 110
    },
    {
      "epoch": 1.3213296398891967,
      "grad_norm": 4.107373237609863,
      "learning_rate": 8.638743455497382e-05,
      "loss": 9.1181,
      "step": 120
    },
    {
      "epoch": 1.4321329639889195,
      "grad_norm": 3.53180193901062,
      "learning_rate": 8.376963350785341e-05,
      "loss": 9.0084,
      "step": 130
    },
    {
      "epoch": 1.5429362880886428,
      "grad_norm": 3.777155876159668,
      "learning_rate": 8.115183246073299e-05,
      "loss": 8.939,
      "step": 140
    },
    {
      "epoch": 1.6537396121883656,
      "grad_norm": 3.6637699604034424,
      "learning_rate": 7.853403141361257e-05,
      "loss": 8.9525,
      "step": 150
    },
    {
      "epoch": 1.7645429362880887,
      "grad_norm": 4.660778999328613,
      "learning_rate": 7.591623036649214e-05,
      "loss": 8.8996,
      "step": 160
    },
    {
      "epoch": 1.8753462603878117,
      "grad_norm": 4.2628984451293945,
      "learning_rate": 7.329842931937174e-05,
      "loss": 8.8998,
      "step": 170
    },
    {
      "epoch": 1.9861495844875345,
      "grad_norm": 4.296296119689941,
      "learning_rate": 7.068062827225132e-05,
      "loss": 8.7898,
      "step": 180
    },
    {
      "epoch": 1.9861495844875345,
      "eval_loss": 2.2037570476531982,
      "eval_runtime": 6.6219,
      "eval_samples_per_second": 56.63,
      "eval_steps_per_second": 7.098,
      "step": 180
    },
    {
      "epoch": 2.0886426592797784,
      "grad_norm": 4.701233386993408,
      "learning_rate": 6.80628272251309e-05,
      "loss": 8.0657,
      "step": 190
    },
    {
      "epoch": 2.1994459833795013,
      "grad_norm": 4.403772354125977,
      "learning_rate": 6.544502617801048e-05,
      "loss": 8.6265,
      "step": 200
    },
    {
      "epoch": 2.3102493074792245,
      "grad_norm": 4.302947998046875,
      "learning_rate": 6.282722513089006e-05,
      "loss": 8.7564,
      "step": 210
    },
    {
      "epoch": 2.4210526315789473,
      "grad_norm": 4.281722068786621,
      "learning_rate": 6.020942408376964e-05,
      "loss": 8.6006,
      "step": 220
    },
    {
      "epoch": 2.5318559556786706,
      "grad_norm": 4.5132269859313965,
      "learning_rate": 5.759162303664922e-05,
      "loss": 8.6059,
      "step": 230
    },
    {
      "epoch": 2.6426592797783934,
      "grad_norm": 4.841737270355225,
      "learning_rate": 5.4973821989528795e-05,
      "loss": 8.6298,
      "step": 240
    },
    {
      "epoch": 2.7534626038781163,
      "grad_norm": 5.5574212074279785,
      "learning_rate": 5.235602094240838e-05,
      "loss": 8.5429,
      "step": 250
    },
    {
      "epoch": 2.864265927977839,
      "grad_norm": 4.908600330352783,
      "learning_rate": 4.973821989528796e-05,
      "loss": 8.5959,
      "step": 260
    },
    {
      "epoch": 2.9750692520775623,
      "grad_norm": 4.591365814208984,
      "learning_rate": 4.7120418848167544e-05,
      "loss": 8.6235,
      "step": 270
    },
    {
      "epoch": 2.9750692520775623,
      "eval_loss": 2.1656079292297363,
      "eval_runtime": 6.584,
      "eval_samples_per_second": 56.956,
      "eval_steps_per_second": 7.138,
      "step": 270
    },
    {
      "epoch": 3.0775623268698062,
      "grad_norm": 5.092480182647705,
      "learning_rate": 4.4502617801047125e-05,
      "loss": 7.7205,
      "step": 280
    },
    {
      "epoch": 3.188365650969529,
      "grad_norm": 5.189202785491943,
      "learning_rate": 4.1884816753926706e-05,
      "loss": 8.606,
      "step": 290
    },
    {
      "epoch": 3.299168975069252,
      "grad_norm": 4.752823829650879,
      "learning_rate": 3.926701570680629e-05,
      "loss": 8.3133,
      "step": 300
    },
    {
      "epoch": 3.409972299168975,
      "grad_norm": 5.004528045654297,
      "learning_rate": 3.664921465968587e-05,
      "loss": 8.5185,
      "step": 310
    },
    {
      "epoch": 3.520775623268698,
      "grad_norm": 4.542727947235107,
      "learning_rate": 3.403141361256545e-05,
      "loss": 8.4408,
      "step": 320
    },
    {
      "epoch": 3.6315789473684212,
      "grad_norm": 4.801759719848633,
      "learning_rate": 3.141361256544503e-05,
      "loss": 8.4109,
      "step": 330
    },
    {
      "epoch": 3.742382271468144,
      "grad_norm": 4.8397955894470215,
      "learning_rate": 2.879581151832461e-05,
      "loss": 8.3746,
      "step": 340
    },
    {
      "epoch": 3.853185595567867,
      "grad_norm": 4.966043949127197,
      "learning_rate": 2.617801047120419e-05,
      "loss": 8.3921,
      "step": 350
    },
    {
      "epoch": 3.96398891966759,
      "grad_norm": 5.29990291595459,
      "learning_rate": 2.3560209424083772e-05,
      "loss": 8.443,
      "step": 360
    },
    {
      "epoch": 3.96398891966759,
      "eval_loss": 2.1481616497039795,
      "eval_runtime": 6.6167,
      "eval_samples_per_second": 56.675,
      "eval_steps_per_second": 7.103,
      "step": 360
    }
  ],
  "logging_steps": 10,
  "max_steps": 450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 90,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.65690837160919e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
