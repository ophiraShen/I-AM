# GLM-1.5B LoRA 微调训练对比

## 1. 训练参数对比

| 参数 | 第一次训练 | 第二次训练 | 第三次训练 | 趋势 |
|------|------------|------------|------------|------|
| 学习率 | 2e-4 | 1e-4 | 8e-5 | ↓ |
| warmup_ratio | 0.1 | 0.15 | 0.15 | → |
| lora_rank | 8 | 16 | 16 | → |
| epochs | 3 | 5 | 5 | → |
| batch_size | 8 | 8 | 8 | → |

## 2. 训练效果对比

| 指标 | 第一次训练 | 第二次训练 | 第三次训练 | 趋势 |
|------|------------|------------|------------|------|
| 初始训练loss | 15.58 | 15.845 | 14.724 | ↓ |
| 最终训练loss | 8.38 | 8.36 | 8.561 | ↑ |
| 初始验证loss | 2.23 | 2.34 | 2.315 | → |
| 最终验证loss | 2.13 | 2.14 | 2.171 | ↑ |

## 3. 训练过程分析

| Epoch | 训练Loss | 验证Loss | 学习率 |
|-------|----------|----------|---------|
| 1.0 | 9.354 | 2.315 | 6.4e-5 |
| 2.0 | 8.846 | 2.224 | 4.8e-5 |
| 3.0 | 8.756 | 2.191 | 3.2e-5 |
| 4.0 | 8.613 | 2.176 | 1.6e-5 |
| 5.0 | 8.561 | 2.171 | 0.0 |